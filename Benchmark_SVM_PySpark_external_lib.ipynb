{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Semiparametric SVM training using subgradients in Spark **\n",
    "\n",
    "#### bla, bla, bla. \n",
    "\n",
    "#### We will benchmark the algorithms with data files from UCI:\n",
    "\n",
    "* **Ripley**, the Ripley dataset\n",
    "* **Kwok**, the Kwok dataset\n",
    "* **Twonorm**, the Twonorm dataset\n",
    "* **Waveform**, the Waveform dataset\n",
    "* **Covertype**, the Covertype dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# definir variable de usuario y ejecutar condicionalmente cualquier código que dependa del contexto de ejecución\n",
    "\n",
    "user = 'navia' # navia, roberto\n",
    "modelo = 'hybrid'\n",
    "\n",
    "if user == 'roberto':\n",
    "    # definir sc\n",
    "    import findspark\n",
    "    findspark.init()\n",
    "    from pyspark import SparkConf, SparkContext\n",
    "    conf = (SparkConf().setMaster(\"local[4]\").setAppName(\"My app\").set(\"spark.executor.memory\", \"2g\"))\n",
    "    sc = SparkContext(conf = conf)\n",
    "\n",
    "if user == 'navia':\n",
    "    sc.addPyFile(\"/export/usuarios01/navia/spark/SVM_spark/common/lib/svm_utils.py\")\n",
    "    sc.addPyFile(\"/export/usuarios01/navia/spark/SVM_spark/common/lib/quadtree_utils.py\")   \n",
    "    import svm_utils as SVM_UTILS\n",
    "    import quadtree_utils as QUADTREE\n",
    "    import numpy as np\n",
    "    from pyspark.mllib.regression import LabeledPoint\n",
    "    import pickle\n",
    "    %matplotlib inline\n",
    "\n",
    "kdatasets = [1, 2, 3, 4]\n",
    "kfold = 1\n",
    "Niter = 150\n",
    "#Niter = 2\n",
    "Nnodes = 32\n",
    "Samplefraction = 0.05\n",
    "\n",
    "NCs = [5, 10, 25, 50, 100, 200]\n",
    "\n",
    "for kdataset in kdatasets:\n",
    "    aucs = []\n",
    "    times = []\n",
    "    x_tr, y_tr, x_tst, y_tst, sigma, C, NC, name_dataset = SVM_UTILS.load_data(kdataset)\n",
    "    XtrRDD = sc.parallelize(np.hstack((y_tr, x_tr)), Nnodes).map(lambda x: LabeledPoint(x[0], x[1:len(x)]))\n",
    "    XtstRDD = sc.parallelize(np.hstack((y_tst, x_tst)), Nnodes).map(lambda x: LabeledPoint(x[0], x[1:len(x)]))\n",
    "    for NC in NCs:\n",
    "        if modelo == 'hybrid':\n",
    "            auc_tst, elapsed_time = SVM_UTILS.train_hybridSVM(XtrRDD, XtstRDD, sigma, C, NC, name_dataset, Niter, Samplefraction)\n",
    "        aucs.append(auc_tst)\n",
    "        times.append(elapsed_time)\n",
    "    print aucs\n",
    "    print times\n",
    "    filename = 'results_dataset_' + str(kdataset) + '_' + modelo + '.pkl'\n",
    "    with open(filename, 'w') as f:\n",
    "        pickle.dump([aucs, times], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
