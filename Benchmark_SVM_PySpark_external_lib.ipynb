{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Semiparametric SVM training using subgradients in Spark **\n",
    "\n",
    "#### bla, bla, bla. \n",
    "\n",
    "#### We will benchmark the algorithms with data files from UCI:\n",
    "\n",
    "* **Ripley**, the Ripley dataset\n",
    "* **Kwok**, the Kwok dataset\n",
    "* **Twonorm**, the Twonorm dataset\n",
    "* **Waveform**, the Waveform dataset\n",
    "* **Covertype**, the Covertype dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset = Ripley, modelo = hybrid, kfold = 1, Niter = 50, NC = 5\n",
      "Training the linear SVM model during 50 iterations\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 Done!\n",
      "Clustering SVs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/spark-1.6.0-bin-2.6.0/python/pyspark/mllib/clustering.py:176: UserWarning: Support for runs is deprecated in 1.6.0. This param will have no effect in 1.7.0.\n",
      "  \"Support for runs is deprecated in 1.6.0. This param will have no effect in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the kernel expansion...\n",
      "Training the hybrid SVM model during 50 iterations\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 Fin!\n",
      "Predicting and evaluating...\n",
      "AUCval = 0.967794, AUCtst = 0.961400\n",
      "Elapsed_time = 262.665087\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b4d179f28a77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m                         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m                             \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mauc_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauc_tst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "# definir variable de usuario y ejecutar condicionalmente cualquier código que dependa del contexto de ejecución\n",
    "# no borrar código, simplemente ejecutarlo o no con un \"if\"\n",
    "# cada uno mantiene actualizada su parte del \"if\" y no toca la del otro\n",
    "\n",
    "user = 'navia'\n",
    "#user = 'roberto'\n",
    "modeloSGMA_IRWLS = True\n",
    "\n",
    "#modelo = 'hybrid' \n",
    "#modelo = 'kernelgrad' \n",
    "overwrite_results = False # overwrites results even when the result file exists, skips the execution otherwise\n",
    "\n",
    "if user == 'roberto':\n",
    "    # definir sc\n",
    "    import findspark\n",
    "    findspark.init()\n",
    "    from pyspark import SparkConf, SparkContext\n",
    "    conf = (SparkConf().setMaster(\"local[4]\").setAppName(\"My app\").set(\"spark.executor.memory\", \"2g\"))\n",
    "    sc = SparkContext(conf = conf)\n",
    "    import common.lib.svm_utils as SVM_UTILS\n",
    "    import common.lib.quadtree_utils as QUADTREE\n",
    "    import numpy as np\n",
    "    from pyspark.mllib.regression import LabeledPoint\n",
    "    import pickle\n",
    "    from math import sqrt\n",
    "    %matplotlib inline \n",
    "\n",
    "\n",
    "if user == 'navia':\n",
    "    sc.addPyFile(\"file:///export/usuarios01/navia/spark/SVM_spark/common/lib/svm_utils.py\")\n",
    "    sc.addPyFile(\"file:///export/usuarios01/navia/spark/SVM_spark/common/lib/quadtree_utils.py\")   \n",
    "    import svm_utils as SVM_UTILS\n",
    "    import IRWLSUtils as IRWLSUtils\n",
    "    import KernelUtils as KernelUtils\n",
    "    import ResultsUtils as ResultsUtils\n",
    "    import SGMAUtils as SGMAUtils\n",
    "    import numpy as np\n",
    "    from pyspark.mllib.regression import LabeledPoint\n",
    "    import pickle\n",
    "    from math import sqrt\n",
    "    %matplotlib inline\n",
    "\n",
    "    \n",
    "if modeloSGMA_IRWLS:\n",
    "\n",
    "    # Esta función habrá que moverla a una librería.\n",
    "    # mllib tiene una función que hace esto pero por alguna razón luego va todo muy lento.\n",
    "    \n",
    "    from sklearn.datasets import load_svmlight_file\n",
    "    from pyspark.mllib.regression import LabeledPoint   \n",
    "    \n",
    "    def loadFile(filename,sc,dimensions):\n",
    "        X,Y = load_svmlight_file(filename,dimensions)\n",
    "        X=X.toarray()\n",
    "        return sc.parallelize(np.concatenate((Y.reshape((len(Y),1)),X),axis=1)).map(lambda x: LabeledPoint(x[0],x[1:]),12)\n",
    "\n",
    "    \n",
    "    # Se importan las funciones\n",
    "    from common.lib.SGMAUtils import SGMA\n",
    "    from common.lib.IRWLSUtils import IRWLS\n",
    "    from common.lib.ResultsUtils import show_results\n",
    "    \n",
    "    # Se carga entrenamiento y test\n",
    "    XtrRDD = loadFile('data/a9a',sc,123)\n",
    "    XtstRDD = loadFile('data/a9a.t',sc,123)\n",
    "    \n",
    "    # Se declaran las variables\n",
    "    datasetSize = XtrRDD.count()\n",
    "    NC = 50\n",
    "    sigma = np.sqrt(123)\n",
    "    gamma = 1.0/(sigma*sigma)\n",
    "    C = 1000\n",
    "    samplingRate=min(1.0,1000.0/datasetSize)    \n",
    "    \n",
    "    # Se ejecuta el algoritmo\n",
    "    Bases = SGMA(XtrRDD,NC,gamma,samplingRate)\n",
    "    Pesos = IRWLS(XtrRDD,Bases,C,gamma)\n",
    "    \n",
    "    show_results(XtstRDD,Bases,Pesos,gamma)     \n",
    "    \n",
    "\n",
    "kdatasets = [1, 2, 3, 4]\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "\n",
    "#Niter = 2\n",
    "Nnodes = 32\n",
    "Samplefraction = 0.05\n",
    "\n",
    "Niter = 150\n",
    "NCs = [5, 10, 25, 50, 100, 200]\n",
    "\n",
    "#Niter = 300\n",
    "#NCs = [50, 100, 200]\n",
    "\n",
    "\n",
    "kdatasets = [1, 2, 3, 4]\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "Niters = [50, 100, 200]\n",
    "NCs = [5, 10, 25, 50, 100, 200]\n",
    "modelos = ['hybrid', 'kernelgrad']\n",
    "#modelos = ['kernelgrad']\n",
    "\n",
    "for modelo in modelos:\n",
    "    for kdataset in kdatasets:\n",
    "        for kfold in folds:\n",
    "            for Niter in Niters:\n",
    "                x_tr, y_tr, x_val, y_val, x_tst, y_tst, name_dataset = SVM_UTILS.load_data(kdataset, kfold)\n",
    "                NI = x_tr.shape[1]\n",
    "                sigma = sqrt(NI)\n",
    "                C = 10.0\n",
    "                XtrRDD = sc.parallelize(np.hstack((y_tr, x_tr)), Nnodes).map(lambda x: LabeledPoint(x[0], x[1:len(x)]))\n",
    "                XvalRDD = sc.parallelize(np.hstack((y_val, x_val)), Nnodes).map(lambda x: LabeledPoint(x[0], x[1:len(x)]))\n",
    "                XtstRDD = sc.parallelize(np.hstack((y_tst, x_tst)), Nnodes).map(lambda x: LabeledPoint(x[0], x[1:len(x)]))\n",
    "                for NC in NCs:\n",
    "                    print \"Dataset = %s, modelo = %s, kfold = %d, Niter = %d, NC = %d\" % (name_dataset, modelo, kfold, Niter, NC)\n",
    "                    filename = './results/dataset_' + str(kdataset) + '_modelo_' + modelo + '_NC_' + str(NC) + '_Niter_' + str(Niter) + '_kfold_' + str(kfold) + '.pkl'\n",
    "                    try:\n",
    "                        f = open(filename,'r')\n",
    "                        f.close()\n",
    "                        file_exists = True\n",
    "                    except:\n",
    "                        file_exists = False\n",
    "                        pass\n",
    "                    execute = False\n",
    "                    if file_exists:\n",
    "                        if overwrite_results:\n",
    "                            execute = True\n",
    "                    else:\n",
    "                        execute = True                                  \n",
    "                    if execute:\n",
    "                        \n",
    "                        if modelo == 'hybrid':\n",
    "                            auc_val, auc_tst, exe_time = SVM_UTILS.train_hybridSVM(XtrRDD, XvalRDD, XtstRDD, sigma, C, NC, name_dataset, Niter, Samplefraction)\n",
    "                        \n",
    "                        if modelo == 'kernelgrad':\n",
    "                            auc_val, auc_tst, exe_time = SVM_UTILS.train_kernelgrad(XtrRDD, XvalRDD, XtstRDD, sigma, C, NC, name_dataset, Niter, Samplefraction)\n",
    "                        \n",
    "                        with open(filename, 'w') as f:\n",
    "                            pickle.dump([auc_val, auc_tst, exe_time], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
