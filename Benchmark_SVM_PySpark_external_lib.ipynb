{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Semiparametric SVM training using subgradients in Spark **\n",
    "\n",
    "#### bla, bla, bla. \n",
    "\n",
    "#### We will benchmark the algorithms with data files from UCI:\n",
    "\n",
    "* **Ripley**, the Ripley dataset\n",
    "* **Kwok**, the Kwok dataset\n",
    "* **Twonorm**, the Twonorm dataset\n",
    "* **Waveform**, the Waveform dataset\n",
    "* **Covertype**, the Covertype dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset = Ripley, modelo = SGMA_IRWLS, kfold = 0, Niter = 50, NC = 50\n",
      "Centroid 1 : Taking candidates, Evaluating ED, Max ED: 61.0033820158 , Updating Matrices Time 1.98006081581\n",
      "Centroid 2 : Taking candidates, Evaluating ED, Max ED: 34.9041569493 , Updating Matrices Time 1.8785738945\n",
      "Centroid 3 : Taking candidates, Evaluating ED, Max ED: 24.9790874445 , Updating Matrices Time 2.99995803833\n",
      "Centroid 4 : Taking candidates, Evaluating ED, Max ED: 29.361431809 , Updating Matrices Time 1.86370611191\n",
      "Centroid 5 : Taking candidates, Evaluating ED, Max ED: 25.0903108008 , Updating Matrices Time 3.05067110062\n",
      "Centroid 6 : Taking candidates, Evaluating ED, Max ED: 20.5076441165 , Updating Matrices Time 3.33322906494\n",
      "Centroid 7 : Taking candidates, Evaluating ED, Max ED: 15.2255407727 , Updating Matrices Time 2.74278092384\n",
      "Centroid 8 : Taking candidates, Evaluating ED, Max ED: 13.5951053286 , Updating Matrices Time 5.99819397926\n",
      "Centroid 9 : Taking candidates, Evaluating ED, Max ED: 11.6187392066 , Updating Matrices Time 3.96301794052\n",
      "Centroid 10 : Taking candidates, Evaluating ED, Max ED: 11.7671180351 , Updating Matrices Time 3.47913813591\n",
      "Centroid 11 : Taking candidates, Evaluating ED, Max ED: 11.9183668549 , Updating Matrices Time 3.54207015038\n",
      "Centroid 12 : Taking candidates, Evaluating ED, Max ED: 13.353593417 , Updating Matrices Time 5.00921297073\n",
      "Centroid 13 : Taking candidates, Evaluating ED, Max ED: 11.0907082729 , Updating Matrices Time 5.07232499123\n",
      "Centroid 14 : Taking candidates, Evaluating ED, Max ED: 5.84071737459 , Updating Matrices Time 3.9696199894\n",
      "Centroid 15 : Taking candidates, Evaluating ED, Max ED: 9.38989644528 , Updating Matrices Time 5.00707316399\n",
      "Centroid 16 : Taking candidates, Evaluating ED, Max ED: 3.72211294025 , Updating Matrices Time 5.06146502495\n",
      "Centroid 17 : Taking candidates, Evaluating ED, Max ED: 4.50034238127 , Updating Matrices Time 3.94971203804\n",
      "Centroid 18 : Taking candidates, Evaluating ED, Max ED: 2.33104089244 , Updating Matrices Time 3.09254193306\n",
      "Centroid 19 : Taking candidates, Evaluating ED, Max ED: 8.89264641955 , Updating Matrices Time 1.97528910637\n",
      "Centroid 20 : Taking candidates, Evaluating ED, Max ED: 10.4334634242 , Updating Matrices Time 4.98130583763\n",
      "Centroid 21 : Taking candidates, Evaluating ED, Max ED: 1.80153728639 , Updating Matrices Time 4.04365801811\n",
      "Centroid 22 : Taking candidates, Evaluating ED, Max ED: 2.68508155184 , Updating Matrices Time 3.9557158947\n",
      "Centroid 23 : Taking candidates, Evaluating ED, Max ED: 1.04144313994 , Updating Matrices Time 5.02970719337\n",
      "Centroid 24 : Taking candidates, Evaluating ED, Max ED: 1.64102171852 , Updating Matrices Time 3.9977581501\n",
      "Centroid 25 : Taking candidates, Evaluating ED, Max ED: 0.899230342266 , Updating Matrices Time 4.00022888184\n",
      "Centroid 26 : Taking candidates, Evaluating ED, Max ED: 1.86305814637 , Updating Matrices Time 4.06983613968\n",
      "Centroid 27 : Taking candidates, Evaluating ED, Max ED: 4.16272244342 , Updating Matrices Time 3.95006895065\n",
      "Centroid 28 : Taking candidates, Evaluating ED, Max ED: 0.566187449779 , Updating Matrices Time 4.0722360611\n",
      "Centroid 29 : Taking candidates, Evaluating ED, Max ED: 0.475585547785 , Updating Matrices Time 4.09696602821\n",
      "Centroid 30 : Taking candidates, Evaluating ED, Max ED: 0.454998063485 , Updating Matrices Time 3.86456990242\n",
      "Centroid 31 : Taking candidates, Evaluating ED, Max ED: 0.34143019705 , Updating Matrices Time 5.00917506218\n",
      "Centroid 32 : Taking candidates, Evaluating ED, Max ED: 0.255075932148 , Updating Matrices Time 5.01012301445\n",
      "Centroid 33 : Taking candidates, Evaluating ED, Max ED: 0.295571356099 , Updating Matrices Time 3.09274792671\n",
      "Centroid 34 : Taking candidates, Evaluating ED, Max ED: 0.189400590229 , Updating Matrices Time 5.98144483566\n",
      "Centroid 35 : Taking candidates, Evaluating ED, Max ED: 0.125615025822 , Updating Matrices Time 5.03231906891\n",
      "Centroid 36 : Taking candidates, Evaluating ED, Max ED: 0.133044269301 , Updating Matrices Time 5.99265480042\n",
      "Centroid 37 : Taking candidates, Evaluating ED, Max ED: 0.05404965146 , Updating Matrices Time 2.55525994301\n",
      "Centroid 38 : Taking candidates, Evaluating ED, Max ED: 0.0427387164342 , Updating Matrices Time 3.41091895103\n",
      "Centroid 39 : Taking candidates, Evaluating ED, Max ED: 0.0495281131007 , Updating Matrices Time 2.77428603172\n",
      "Centroid 40 : Taking candidates, Evaluating ED, Max ED: 0.0360036506391 , Updating Matrices Time 3.69607806206\n",
      "Centroid 41 : Taking candidates, Evaluating ED, Max ED: 0.0293294399712 , Updating Matrices Time 2.65556287766\n",
      "Centroid 42 : Taking candidates, Evaluating ED, Max ED: 0.0137257093575 , Updating Matrices Time 3.90604710579\n",
      "Centroid 43 : Taking candidates, Evaluating ED, Max ED: 0.0118295290037 , Updating Matrices Time 3.0052921772\n",
      "Centroid 44 : Taking candidates, Evaluating ED, Max ED: 0.0449289781468 , Updating Matrices Time 2.05609798431\n",
      "Centroid 45 : Taking candidates, Evaluating ED, Max ED: 0.0196383108624 , Updating Matrices Time 3.0153529644\n",
      "Centroid 46 : Taking candidates, Evaluating ED, Max ED: 0.0105204738101 , Updating Matrices Time 1.95744800568\n",
      "Centroid 47 : Taking candidates, Evaluating ED, Max ED: 0.0110494209646 , Updating Matrices Time 1.73869800568\n",
      "Centroid 48 : Taking candidates, Evaluating ED, Max ED: 0.00495298413086 , Updating Matrices Time 3.26363992691\n",
      "Centroid 49 : Taking candidates, Evaluating ED, Max ED: 0.00534663826226 , Updating Matrices Time 4.06630206108\n",
      "Centroid 50 : Taking candidates, Evaluating ED, Max ED: 0.00639991509394 , Updating Matrices Time 5.04557204247\n",
      "Iteration 1 : DeltaW/W inf , Iteration Time 1.87428402901\n",
      "Iteration 2 : DeltaW/W 10.9664664504 , Iteration Time 1.05788803101\n",
      "Iteration 3 : DeltaW/W 0.738682231169 , Iteration Time 0.21929192543\n",
      "Iteration 4 : DeltaW/W 0.77178814016 , Iteration Time 0.235785961151\n",
      "Iteration 5 : DeltaW/W 1.01640894928 , Iteration Time 0.226614952087\n",
      "Iteration 6 : DeltaW/W 0.68016823117 , Iteration Time 0.255748987198\n",
      "Iteration 7 : DeltaW/W 0.758927268519 , Iteration Time 2.06439399719\n",
      "Iteration 8 : DeltaW/W 0.657005494339 , Iteration Time 1.11288809776\n",
      "Iteration 9 : DeltaW/W 0.26134713173 , Iteration Time 0.891005992889\n",
      "AUCval = 0.927536, AUCtst = 0.959108\n",
      "Elapsed_time = 206.534081\n"
     ]
    }
   ],
   "source": [
    "# definir variable de usuario y ejecutar condicionalmente cualquier código que dependa del contexto de ejecución\n",
    "# no borrar código, simplemente ejecutarlo o no con un \"if\"\n",
    "# cada uno mantiene actualizada su parte del \"if\" y no toca la del otro\n",
    "\n",
    "user = 'navia'\n",
    "#user = 'roberto'\n",
    "modeloSGMA_IRWLS = True\n",
    "Nnodes = 32\n",
    "Samplefraction = 0.05\n",
    "\n",
    "#modelo = 'hybrid' \n",
    "#modelo = 'kernelgrad' \n",
    "overwrite_results = False # overwrites results even when the result file exists, skips the execution otherwise\n",
    "\n",
    "if user == 'roberto':\n",
    "    # definir sc\n",
    "    import findspark\n",
    "    findspark.init()\n",
    "    from pyspark import SparkConf, SparkContext\n",
    "    conf = (SparkConf().setMaster(\"local[4]\").setAppName(\"My app\").set(\"spark.executor.memory\", \"2g\"))\n",
    "    sc = SparkContext(conf = conf)\n",
    "    import common.lib.svm_utils as SVM_UTILS\n",
    "    import common.lib.quadtree_utils as QUADTREE\n",
    "    import numpy as np\n",
    "    from pyspark.mllib.regression import LabeledPoint\n",
    "    import pickle\n",
    "    from math import sqrt\n",
    "    %matplotlib inline\n",
    "    # Se importan las funciones\n",
    "    from common.lib.SGMAUtils import SGMA\n",
    "    from common.lib.IRWLSUtils import IRWLS\n",
    "    from common.lib.ResultsUtils import show_results\n",
    "\n",
    "\n",
    "\n",
    "if user == 'navia':\n",
    "    sc.addPyFile(\"file:///export/usuarios01/navia/spark/SVM_spark/common/lib/svm_utils.py\")\n",
    "    sc.addPyFile(\"file:///export/usuarios01/navia/spark/SVM_spark/common/lib/IRWLSUtils.py\")   \n",
    "    sc.addPyFile(\"file:///export/usuarios01/navia/spark/SVM_spark/common/lib/KernelUtils.py\")   \n",
    "    sc.addPyFile(\"file:///export/usuarios01/navia/spark/SVM_spark/common/lib/ResultsUtils.py\")   \n",
    "    sc.addPyFile(\"file:///export/usuarios01/navia/spark/SVM_spark/common/lib/SGMAUtils.py\")   \n",
    "    import svm_utils as SVM_UTILS\n",
    "    #from SGMAUtils import SGMA\n",
    "    from IRWLSUtils import loadFile, train_SGMA_IRWLS\n",
    "    #from ResultsUtils import compute_AUCs\n",
    "    import numpy as np\n",
    "    from pyspark.mllib.regression import LabeledPoint\n",
    "    import pickle\n",
    "    from math import sqrt\n",
    "    %matplotlib inline\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "'''    \n",
    "if modeloSGMA_IRWLS:\n",
    "\n",
    "    # Esta función habrá que moverla a una librería.\n",
    "    # mllib tiene una función que hace esto pero por alguna razón luego va todo muy lento.\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Se carga entrenamiento y test\n",
    "    XtrRDD = loadFile('data/a9a',sc,123)\n",
    "    XtstRDD = loadFile('data/a9a.t',sc,123)\n",
    "    \n",
    "    # Se declaran las variables\n",
    "    datasetSize = XtrRDD.count()\n",
    "    NC = 50\n",
    "    sigma = np.sqrt(123)\n",
    "    gamma = 1.0/(sigma*sigma)\n",
    "    C = 1000\n",
    "    samplingRate=min(1.0,1000.0/datasetSize)    \n",
    "    \n",
    "    # Se ejecuta el algoritmo\n",
    "    Bases = SGMA(XtrRDD,NC,gamma,samplingRate)\n",
    "    Pesos = IRWLS(XtrRDD,Bases,C,gamma)\n",
    "    \n",
    "    show_results(XtstRDD,Bases,Pesos,gamma)     \n",
    "'''\n",
    "\n",
    "# 0 = Ripley\n",
    "# 1 = Kwok\n",
    "# 2 = Twonorm\n",
    "# 3 = Waveform\n",
    "# 4 = Adult\n",
    "\n",
    "datasets = [0, 1, 2, 3, 4]\n",
    "folds = [0, 1, 2, 3, 4]\n",
    "dataset_names = ['Ripley', 'Kwok', 'Twonorm', 'Waveform', 'Adult']\n",
    "Niters = [50, 100, 200]\n",
    "NCs = [5, 10, 25, 50, 100, 200]\n",
    "modelos = ['hybrid', 'kernelgrad', 'SGMA_IRWLS']\n",
    "\n",
    "datasets = [0]\n",
    "folds = [0]\n",
    "modelos = ['SGMA_IRWLS']\n",
    "Niters = [50]\n",
    "NCs = [50]\n",
    "\n",
    "for modelo in modelos:\n",
    "    for kdataset in datasets:\n",
    "        for kfold in folds:\n",
    "            for Niter in Niters:\n",
    "                \n",
    "                if kdataset in [0, 1, 2, 3]: # loading from .mat\n",
    "                    x_tr, y_tr, x_val, y_val, x_tst, y_tst = SVM_UTILS.load_data(kdataset, kfold)\n",
    "                    name_dataset = dataset_names[kdataset]\n",
    "                    NI = x_tr.shape[1]\n",
    "                    sigma = sqrt(NI)\n",
    "                    C = 10.0\n",
    "                    XtrRDD = sc.parallelize(np.hstack((y_tr, x_tr)), Nnodes).map(lambda x: LabeledPoint(x[0], x[1:len(x)]))\n",
    "                    XvalRDD = sc.parallelize(np.hstack((y_val, x_val)), Nnodes).map(lambda x: LabeledPoint(x[0], x[1:len(x)]))\n",
    "                    XtstRDD = sc.parallelize(np.hstack((y_tst, x_tst)), Nnodes).map(lambda x: LabeledPoint(x[0], x[1:len(x)]))\n",
    "                    XtrRDD.cache()\n",
    "                    XvalRDD.cache()\n",
    "                    XtstRDD.cache()               \n",
    "\n",
    "                if kdataset in [4]: # loading libsvm format\n",
    "                    name_dataset = dataset_names[kdataset]\n",
    "                    XtrRDD = loadFile('./data/' + name_dataset.lower() + '_train',sc,123)\n",
    "                    XvalRDD = loadFile('./data/' + name_dataset.lower() + '_val',sc,123)\n",
    "                    XtstRDD = loadFile('./data/' + name_dataset.lower() + '_test',sc,123)\n",
    "                    XtrRDD.cache()\n",
    "                    XvalRDD.cache()\n",
    "                    XtstRDD.cache()\n",
    "                    sigma = np.sqrt(123)\n",
    "                    \n",
    "\n",
    "                for NC in NCs:\n",
    "                    print \"Dataset = %s, modelo = %s, kfold = %d, Niter = %d, NC = %d\" % (name_dataset, modelo, kfold, Niter, NC)\n",
    "                    filename = './results/dataset_' + str(kdataset) + '_modelo_' + modelo + '_NC_' + str(NC) + '_Niter_' + str(Niter) + '_kfold_' + str(kfold) + '.pkl'\n",
    "                    #import code\n",
    "                    #code.interact(local=locals())\n",
    "                    try:\n",
    "                        f = open(filename,'r')\n",
    "                        f.close()\n",
    "                        file_exists = True\n",
    "                    except:\n",
    "                        file_exists = False\n",
    "                        pass\n",
    "                    execute = False\n",
    "                    if file_exists:\n",
    "                        if overwrite_results:\n",
    "                            execute = True\n",
    "                    else:\n",
    "                        execute = True                                  \n",
    "                    if execute:\n",
    "\n",
    "                        if modelo == 'hybrid':\n",
    "                            auc_val, auc_tst, exe_time = SVM_UTILS.train_hybridSVM(XtrRDD, XvalRDD, XtstRDD, sigma, C, NC, name_dataset, Niter, Samplefraction)\n",
    "\n",
    "                        if modelo == 'kernelgrad':\n",
    "                            auc_val, auc_tst, exe_time = SVM_UTILS.train_kernelgrad(XtrRDD, XvalRDD, XtstRDD, sigma, C, NC, name_dataset, Niter, Samplefraction)\n",
    "\n",
    "                        if modelo == 'SGMA_IRWLS':\n",
    "                            auc_val, auc_tst, exe_time = train_SGMA_IRWLS(XtrRDD, XvalRDD, XtstRDD, sigma, C, NC, name_dataset, Niter, Samplefraction)\n",
    "                            \n",
    "                        with open(filename, 'w') as f:\n",
    "                            pickle.dump([auc_val, auc_tst, exe_time], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
