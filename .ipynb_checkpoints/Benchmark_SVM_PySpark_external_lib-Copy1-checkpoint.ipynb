{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Semiparametric SVM training using subgradients in Spark **\n",
    "\n",
    "#### bla, bla, bla. \n",
    "\n",
    "#### We will benchmark the algorithms with data files from UCI:\n",
    "\n",
    "* **Ripley**, the Ripley dataset\n",
    "* **Kwok**, the Kwok dataset\n",
    "* **Twonorm**, the Twonorm dataset\n",
    "* **Waveform**, the Waveform dataset\n",
    "* **Covertype**, the Covertype dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset = Higgs, modelo = SGMA_IRWLS, kfold = 0, Niter = 300, NC = 20\n",
      "Mapping labels to (-1, 1)...\n",
      "Centroid 1 : Taking candidates, Evaluating ED, Max ED: 137.151537228 , Updating Matrices Time 31.3840889931\n",
      "Centroid 2 : Taking candidates, Evaluating ED, Max ED: 74.2827288172 , Updating Matrices Time 46.7039761543\n",
      "Centroid 3 : Taking candidates, Evaluating ED, Max ED: 38.9031665401 , Updating Matrices Time 55.2168498039\n",
      "Centroid 4 : Taking candidates, Evaluating ED, Max ED: 24.5646520737 , Updating Matrices Time 64.4517290592\n",
      "Centroid 5 : Taking candidates, Evaluating ED, Max ED: 23.2463271574 , Updating Matrices Time 73.6322140694\n",
      "Centroid 6 : Taking candidates, Evaluating ED, Max ED: 15.5201564549 , Updating Matrices Time 83.5717589855\n",
      "Centroid 7 : Taking candidates, Evaluating ED, Max ED: 24.2534756705 , Updating Matrices Time 92.4235229492\n",
      "Centroid 8 : Taking candidates, Evaluating ED, Max ED: 21.5915900584 , Updating Matrices Time 101.881195068\n",
      "Centroid 9 : Taking candidates, Evaluating ED, Max ED: 23.1395057447 , Updating Matrices Time 111.206765175\n",
      "Centroid 10 : Taking candidates, Evaluating ED, Max ED: 30.9283528832 , Updating Matrices Time 120.531297922\n",
      "Centroid 11 : Taking candidates, Evaluating ED, Max ED: 16.5067910603 , Updating Matrices Time 70.7944300175\n",
      "Centroid 12 : Taking candidates, Evaluating ED, Max ED: 17.1785469685 , Updating Matrices Time 74.6873109341\n",
      "Centroid 13 : Taking candidates, Evaluating ED, Max ED: 18.6490029615 , Updating Matrices Time 78.4115350246\n",
      "Centroid 14 : Taking candidates, Evaluating ED, Max ED: 19.2926854544 , Updating Matrices Time 83.3419921398\n",
      "Centroid 15 : Taking candidates, Evaluating ED, Max ED: 16.759205391 , Updating Matrices Time 86.0534739494\n",
      "Centroid 16 : Taking candidates, Evaluating ED, Max ED: 16.4873103638 , Updating Matrices Time 89.7819228172\n",
      "Centroid 17 : Taking candidates, Evaluating ED, Max ED: 60.9527017048 , Updating Matrices Time 92.6466948986\n",
      "Centroid 18 : Taking candidates, Evaluating ED, Max ED: 15.1351504309 , Updating Matrices Time 98.3083050251\n",
      "Centroid 19 : Taking candidates, Evaluating ED, Max ED: 15.99070416 , Updating Matrices Time 100.325403214\n",
      "Centroid 20 : Taking candidates, Evaluating ED, Max ED: 17.2691610271 , Updating Matrices Time 106.30975008\n",
      "Iteration 1 : DeltaW/W inf , Iteration Time 145.073812008\n",
      "Iteration 2 : DeltaW/W 0.928652162289 , Iteration Time 144.826941967\n",
      "Iteration 3 : DeltaW/W 0.405485765441 , Iteration Time 144.674394131\n",
      "Iteration 4 : DeltaW/W 0.206040023519 , Iteration Time 145.477765083\n",
      "Iteration 5 : DeltaW/W 0.102173125672 , Iteration Time 139.456830978\n",
      "Iteration 6 : DeltaW/W 0.0635462933212 , Iteration Time 139.058465958\n",
      "Iteration 7 : DeltaW/W 0.0446204605894 , Iteration Time 140.089743853\n",
      "Iteration 8 : DeltaW/W 0.0336618909783 , Iteration Time 140.868048906\n",
      "Iteration 9 : DeltaW/W 0.0257655054869 , Iteration Time 141.501981974\n",
      "Iteration 10 : DeltaW/W 0.0204529143036 , Iteration Time 141.65109992\n",
      "Iteration 11 : DeltaW/W 0.0165717409079 , Iteration Time 140.826967955\n",
      "Iteration 12 : DeltaW/W 0.0139029866996 , Iteration Time 139.980505228\n",
      "Iteration 13 : DeltaW/W 0.0121161379068 , Iteration Time 139.99310708\n",
      "Iteration 14 : DeltaW/W 0.0110200007298 , Iteration Time 140.227860928\n",
      "Iteration 15 : DeltaW/W 0.0103800343137 , Iteration Time 140.854030848\n",
      "Iteration 16 : DeltaW/W 0.00998787955666 , Iteration Time 141.651836157\n",
      "Iteration 17 : DeltaW/W 0.00977299412578 , Iteration Time 140.315253973\n",
      "Iteration 18 : DeltaW/W 0.00962914880872 , Iteration Time 140.300986052\n",
      "Iteration 19 : DeltaW/W 0.00948734725535 , Iteration Time 140.431241035\n",
      "Iteration 20 : DeltaW/W 0.00931713095705 , Iteration Time 139.39171195\n",
      "Iteration 21 : DeltaW/W 0.00913732263683 , Iteration Time 140.881479979\n",
      "Iteration 22 : DeltaW/W 0.00896302589733 , Iteration Time 102.47112608\n",
      "Iteration 23 : DeltaW/W 0.00874613315158 , Iteration Time 101.561537981\n",
      "Iteration 24 : DeltaW/W 0.00853106866686 , Iteration Time 102.185961962\n",
      "Iteration 25 : DeltaW/W 0.00831256837881 , Iteration Time 101.917793036\n",
      "Iteration 26 : DeltaW/W 0.00808853751402 , Iteration Time 102.387793064\n",
      "Iteration 27 : DeltaW/W 0.00786887499245 , Iteration Time 98.6907579899\n",
      "Iteration 28 : DeltaW/W 0.00759447359999 , Iteration Time 89.2247781754\n",
      "Iteration 29 : DeltaW/W 0.00733241373315 , Iteration Time 70.1943700314\n",
      "Iteration 30 : DeltaW/W 0.00707675076734 , Iteration Time 69.6873340607\n",
      "Iteration 31 : DeltaW/W 0.00681394614991 , Iteration Time 68.1954917908\n",
      "Iteration 32 : DeltaW/W 0.00657551785888 , Iteration Time 70.0561411381\n",
      "Iteration 33 : DeltaW/W 0.00634279075747 , Iteration Time 70.566671133\n",
      "Iteration 34 : DeltaW/W 0.00611313323116 , Iteration Time 69.2604370117\n",
      "Iteration 35 : DeltaW/W 0.00589740499584 , Iteration Time 69.8965291977\n",
      "Iteration 36 : DeltaW/W 0.00567641898829 , Iteration Time 70.1979339123\n",
      "Iteration 37 : DeltaW/W 0.00547303947771 , Iteration Time 69.5970520973\n",
      "Iteration 38 : DeltaW/W 0.00529381052952 , Iteration Time 69.0377078056\n",
      "Iteration 39 : DeltaW/W 0.0051357573194 , Iteration Time 70.5224349499\n",
      "Iteration 40 : DeltaW/W 0.00497412432647 , Iteration Time 70.0446770191\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-fa824b49a976>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mmodelo\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'SGMA_IRWLS'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m                             \u001b[0mauc_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauc_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauc_tst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexe_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_SGMA_IRWLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrRDD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXvalRDD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtstRDD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNiter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mmodelo\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'LinearSVM'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/export/workdir/spark/tmp/spark-7727a9cf-1609-41aa-a72c-18c92d50e41e/userFiles-00a36a70-ba24-49bf-98cd-cff8909dc131/IRWLSUtils.py\u001b[0m in \u001b[0;36mtrain_SGMA_IRWLS\u001b[1;34m(XtrRDD, XvalRDD, XtstRDD, sigma, C, NC, Niter)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[0mBases\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSGMA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrRDD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msamplingRate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m     \u001b[0mPesos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIRWLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrRDD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mBases\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[0mauc_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauc_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauc_tst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_AUCs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrRDD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXvalRDD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtstRDD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBases\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mPesos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/export/workdir/spark/tmp/spark-7727a9cf-1609-41aa-a72c-18c92d50e41e/userFiles-00a36a70-ba24-49bf-98cd-cff8909dc131/IRWLSUtils.py\u001b[0m in \u001b[0;36mIRWLS\u001b[1;34m(originaldataset, Bases, C, sigma, Niter)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;31m# IRWLS Procedure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0mK1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mK2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_getK1andK2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mBeta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m         \u001b[0mK1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnBases\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnBases\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mK1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnBases\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnBases\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mKC\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/spark-1.6.0-bin-2.6.0/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mreduce\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    795\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 797\u001b[1;33m         \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    798\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/spark-1.6.0-bin-2.6.0/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    769\u001b[0m         \"\"\"\n\u001b[0;32m    770\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m             \u001b[0mport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/spark-1.6.0-bin-2.6.0/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m         return_value = get_return_value(\n\u001b[0;32m    813\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[1;32m/opt/spark-1.6.0-bin-2.6.0/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command, retry)\u001b[0m\n\u001b[0;32m    624\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 626\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_give_back_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/spark-1.6.0-bin-2.6.0/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command)\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msendall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m             \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Answer received: {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m             \u001b[1;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib64/python2.7/socket.pyc\u001b[0m in \u001b[0;36mreadline\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    432\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m                         \u001b[1;32mwhile\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m                             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m                                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# definir variable de usuario y ejecutar condicionalmente cualquier código que dependa del contexto de ejecución\n",
    "# no borrar código, simplemente ejecutarlo o no con un \"if\"\n",
    "# cada uno mantiene actualizada su parte del \"if\" y no toca la del otro\n",
    "\n",
    "user = 'navia'\n",
    "#user = 'roberto'\n",
    "\n",
    "#modelo = 'hybrid' \n",
    "#modelo = 'kernelgrad' \n",
    "overwrite_results = True # overwrites results even when the result file exists, skips the execution otherwise\n",
    "\n",
    "if user == 'roberto':\n",
    "    # definir sc\n",
    "    import findspark\n",
    "    findspark.init()\n",
    "    from pyspark import SparkConf, SparkContext\n",
    "    conf = (SparkConf().setMaster(\"local[4]\").setAppName(\"My app\").set(\"spark.executor.memory\", \"2g\"))\n",
    "    sc = SparkContext(conf = conf)\n",
    "    import common.lib.svm_utils as SVM_UTILS\n",
    "    import numpy as np\n",
    "    from pyspark.mllib.regression import LabeledPoint\n",
    "    import pickle\n",
    "    from math import sqrt\n",
    "    %matplotlib inline\n",
    "    # Se importan las funciones\n",
    "    from pyspark.mllib.util import MLUtils\n",
    "    from common.lib.IRWLSUtils import *\n",
    "    Npartitions = 12\n",
    "    Samplefraction = 0.05\n",
    "\n",
    "if user == 'navia':\n",
    "    sc.addPyFile(\"file:///export/usuarios01/navia/spark/SVM_spark/common/lib/svm_utils.py\")\n",
    "    sc.addPyFile(\"file:///export/usuarios01/navia/spark/SVM_spark/common/lib/IRWLSUtils.py\")   \n",
    "    sc.addPyFile(\"file:///export/usuarios01/navia/spark/SVM_spark/common/lib/KernelUtils.py\")   \n",
    "    sc.addPyFile(\"file:///export/usuarios01/navia/spark/SVM_spark/common/lib/ResultsUtils.py\")   \n",
    "    sc.addPyFile(\"file:///export/usuarios01/navia/spark/SVM_spark/common/lib/SGMAUtils.py\")   \n",
    "    import svm_utils as SVM_UTILS\n",
    "    #from SGMAUtils import SGMA\n",
    "    from IRWLSUtils import loadFile, train_SGMA_IRWLS, train_random_IRWLS, train_hybrid_SGMA_IRWLS, train_kmeans_IRWLS\n",
    "    #from ResultsUtils import compute_AUCs\n",
    "    import numpy as np\n",
    "    from pyspark.mllib.regression import LabeledPoint\n",
    "    from pyspark.mllib.linalg import SparseVector, DenseVector\n",
    "    import pickle\n",
    "    from math import sqrt\n",
    "    from pyspark.mllib.util import MLUtils\n",
    "    %matplotlib inline\n",
    "    Npartitions = -99 # cuando es menor que 0, no se aplica y se deja libre\n",
    "    Samplefraction = 0.05\n",
    "\n",
    "# 0 = Ripley\n",
    "# 1 = Kwok\n",
    "# 2 = Twonorm\n",
    "# 3 = Waveform\n",
    "# 4 = Adult\n",
    "# 5 = SUSY\n",
    "# 6 = KddCup1999, requiere preprocesado...\n",
    "# 7 = Higgs\n",
    "\n",
    "datasets = [0, 1, 2, 3, 4, 5, 6]\n",
    "folds = [0, 1, 2, 3, 4]\n",
    "dataset_names = ['Ripley', 'Kwok', 'Twonorm', 'Waveform', 'Adult', 'Susy', 'KddCup1999', 'Higgs']\n",
    "Niters = [50, 100, 200]\n",
    "NCs = [5, 10, 25, 50, 100, 200]\n",
    "modelos = ['hybridgrad', 'kernelgrad', 'SGMA_IRWLS', 'LinearSVM', 'Logistic', 'random_IRWLS', 'hybrid_IRWLS', 'Kmeans_IRWLS']\n",
    "\n",
    "datasets = [7]\n",
    "folds = [0]\n",
    "modelos = ['SGMA_IRWLS']\n",
    "Niters = [300]\n",
    "NCs = [200]\n",
    "Samplefraction = 0.05\n",
    "\n",
    "for modelo in modelos:\n",
    "    for kdataset in datasets:\n",
    "        for kfold in folds:\n",
    "            for Niter in Niters:\n",
    "                C = 100.0\n",
    "                name_dataset = dataset_names[kdataset]\n",
    "                \n",
    "                #####################################################################################################################\n",
    "                # DATA LOADING: the result of this part must always be three RDDs for train, val and test, containing labelled points.\n",
    "                #####################################################################################################################\n",
    "                if kdataset in [0, 1, 2, 3]: # loading from .mat\n",
    "                    x_tr, y_tr, x_val, y_val, x_tst, y_tst = SVM_UTILS.load_data(kdataset, kfold)\n",
    "                    NI = x_tr.shape[1]\n",
    "                    sigma = sqrt(NI)\n",
    "                    \n",
    "                    if Npartitions > 0:\n",
    "                        XtrRDD = sc.parallelize(np.hstack((y_tr, x_tr)), Npartitions).map(lambda x: LabeledPoint(x[0], x[1:]))\n",
    "                        XvalRDD = sc.parallelize(np.hstack((y_val, x_val)), Npartitions).map(lambda x: LabeledPoint(x[0], x[1:]))\n",
    "                        XtstRDD = sc.parallelize(np.hstack((y_tst, x_tst)), Npartitions).map(lambda x: LabeledPoint(x[0], x[1:]))\n",
    "                    else:\n",
    "                        XtrRDD = sc.parallelize(np.hstack((y_tr, x_tr))).map(lambda x: LabeledPoint(x[0], x[1:]))\n",
    "                        XvalRDD = sc.parallelize(np.hstack((y_val, x_val))).map(lambda x: LabeledPoint(x[0], x[1:]))\n",
    "                        XtstRDD = sc.parallelize(np.hstack((y_tst, x_tst))).map(lambda x: LabeledPoint(x[0], x[1:]))\n",
    "                       \n",
    "                        \n",
    "                if kdataset in [4]: # loading libsvm format\n",
    "                    if kdataset == 4:\n",
    "                        dimensions = 123                       \n",
    "                    print \"Loading \" + name_dataset\n",
    "                    XtrRDD = loadFile('./data/' + name_dataset.lower() + '_train',sc,dimensions,Npartitions)\n",
    "                    XvalRDD = loadFile('./data/' + name_dataset.lower() + '_val',sc,dimensions,Npartitions)\n",
    "                    XtstRDD = loadFile('./data/' + name_dataset.lower() + '_test',sc,dimensions,Npartitions)\n",
    "                    sigma = np.sqrt(dimensions)\n",
    "                    \n",
    "                if kdataset in [5]: # loading in libsvm format and splitting RDD\n",
    "                    if kdataset == 5:\n",
    "                        filename = 'file:///export/usuarios01/navia/spark/SVM_spark/data/SUSY.txt'\n",
    "                        #filename = 'file:///export/usuarios01/navia/spark/SVM_spark/data/minisusy.txt'\n",
    "                        dimensions = 18\n",
    "                    rawdata = MLUtils.loadLibSVMFile(sc, filename)\n",
    "                    # Labelled points are sparse, we map the values\n",
    "                    rawdata = rawdata.map(lambda x: LabeledPoint(x.label, DenseVector((x.features).toArray())  ))\n",
    "                    XtrRDD, XvalRDD, XtstRDD = rawdata.randomSplit(weights=[0.7, 0.1, 0.2], seed=1234)\n",
    "                    sigma = np.sqrt(dimensions)\n",
    "\n",
    "                if kdataset in [7]: # loading as text, transforming to labelledpoint and splitting RDD into train, val and test\n",
    "                    if kdataset == 7:\n",
    "                        \n",
    "                        filename = 'file:///export/g2pi/SPARK/data/higgs_tr.txt'\n",
    "                        XtrRDD = sc.textFile(filename)\n",
    "                        XtrRDD = XtrRDD.map(SVM_UTILS.text2labeled)\n",
    "\n",
    "                        filename = 'file:///export/g2pi/SPARK/data/higgs_val.txt'\n",
    "                        XvalRDD = sc.textFile(filename)\n",
    "                        XvalRDD = XvalRDD.map(SVM_UTILS.text2labeled)\n",
    "                                                \n",
    "                        filename = 'file:///export/g2pi/SPARK/data/higgs_tst.txt'\n",
    "                        XtstRDD = sc.textFile(filename)\n",
    "                        XtstRDD = XtstRDD.map(SVM_UTILS.text2labeled)\n",
    "                        sigma = np.sqrt(len(XtstRDD.take(1)[0].features))\n",
    "\n",
    "                        XtrRDD.cache()\n",
    "                        XvalRDD.cache()\n",
    "                        XtstRDD.cache()\n",
    "\n",
    "                #################################   END LOADING DATA ##########################################################\n",
    "                \n",
    "                for NC in NCs:\n",
    "                    print \"Dataset = %s, modelo = %s, kfold = %d, Niter = %d, NC = %d\" % (name_dataset, modelo, kfold, Niter, NC)\n",
    "                    filename = './results/dataset_' + str(kdataset) + '_modelo_' + modelo + '_NC_' + str(NC) + '_Niter_' + str(Niter) + '_kfold_' + str(kfold) + '.pkl'\n",
    "                    #import code\n",
    "                    #code.interact(local=locals())\n",
    "                    try:\n",
    "                        f = open(filename,'r')\n",
    "                        f.close()\n",
    "                        file_exists = True\n",
    "                    except:\n",
    "                        file_exists = False\n",
    "                        pass\n",
    "                    execute = False\n",
    "                    if file_exists:\n",
    "                        if overwrite_results:\n",
    "                            execute = True\n",
    "                    else:\n",
    "                        execute = True                                  \n",
    "                    if execute:\n",
    "\n",
    "                        if modelo == 'hybridgrad':\n",
    "                            auc_tr, auc_val, auc_tst, exe_time = SVM_UTILS.train_hybridSVM(XtrRDD, XvalRDD, XtstRDD, sigma, C, NC, Niter, Samplefraction)\n",
    "\n",
    "                        if modelo == 'kernelgrad':\n",
    "                            auc_tr, auc_val, auc_tst, exe_time = SVM_UTILS.train_kernelgrad(XtrRDD, XvalRDD, XtstRDD, sigma, C, NC, Niter, Samplefraction)\n",
    "\n",
    "                        if modelo == 'SGMA_IRWLS':\n",
    "                            auc_tr, auc_val, auc_tst, exe_time = train_SGMA_IRWLS(XtrRDD, XvalRDD, XtstRDD, sigma, C, NC, Niter)\n",
    "\n",
    "                        if modelo == 'LinearSVM':\n",
    "                            auc_tr, auc_val, auc_tst, exe_time = SVM_UTILS.train_linear_SVM(XtrRDD, XvalRDD, XtstRDD)\n",
    "                                                \n",
    "                        if modelo == 'Logistic':\n",
    "                            auc_tr, auc_val, auc_tst, exe_time = SVM_UTILS.train_logistic(XtrRDD, XvalRDD, XtstRDD)\n",
    "\n",
    "                        if modelo == 'random_IRWLS':\n",
    "                            auc_tr, auc_val, auc_tst, exe_time = train_random_IRWLS(XtrRDD, XvalRDD, XtstRDD, sigma, C, NC, Niter)\n",
    "\n",
    "                        if modelo == 'hybrid_IRWLS':\n",
    "                            auc_tr, auc_val, auc_tst, exe_time = train_hybrid_SGMA_IRWLS(XtrRDD, XvalRDD, XtstRDD, sigma, C, NC, Niter)\n",
    "\n",
    "                        if modelo == 'Kmeans_IRWLS':\n",
    "                            auc_tr, auc_val, auc_tst, exe_time = train_kmeans_IRWLS(XtrRDD, XvalRDD, XtstRDD, sigma, C, NC, Niter)\n",
    "\n",
    "                        print \"Dataset = %s, modelo = %s, kfold = %d, Niter = %d, NC = %d\" % (name_dataset, modelo, kfold, Niter, NC)\n",
    "                        print \"AUCtr = %f, AUCval = %f, AUCtst = %f\" % (auc_tr, auc_val, auc_tst)\n",
    "                        print \"Elapsed minutes = %f\" % (exe_time / 60.0)\n",
    "\n",
    "                        with open(filename, 'w') as f:\n",
    "                            pickle.dump([auc_tr, auc_val, auc_tst, exe_time], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
