{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Semiparametric SVM training using subgradients in Spark **\n",
    "\n",
    "#### bla, bla, bla. \n",
    "\n",
    "#### We will benchmark the algorithms with data files from UCI:\n",
    "\n",
    "* **Ripley**, the Ripley dataset\n",
    "* **Kwok**, the Kwok dataset\n",
    "* **Twonorm**, the Twonorm dataset\n",
    "* **Waveform**, the Waveform dataset\n",
    "* **Covertype**, the Covertype dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset = Ripley, modelo = kernelgrad, kfold = 1, Niter = 50, NC = 5\n",
      "Clustering data...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'Xtr1RDD' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a373abf781ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    467\u001b[0m                             \u001b[0mauc_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauc_tst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexe_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_hybridSVM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrRDD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXvalRDD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtstRDD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNiter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSamplefraction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mmodelo\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'kernelgrad'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 469\u001b[1;33m                             \u001b[0mauc_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauc_tst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexe_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_kernelgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrRDD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXvalRDD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtstRDD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNiter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSamplefraction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    470\u001b[0m                         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m                             \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mauc_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauc_tst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-a373abf781ed>\u001b[0m in \u001b[0;36mtrain_kernelgrad\u001b[1;34m(XtrRDD, XvalRDD, XtstRDD, sigma, C, NC, name_dataset, Niter, Samplefraction)\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Clustering data...\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[1;31m#SV_RDD = Xtr1RDD.filter(lambda x: in_margin(x, w))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m     \u001b[0mclusters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtr1RDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxIterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mruns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializationMode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"random\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclusters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcenters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'Xtr1RDD' is not defined"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "from pyspark.mllib.clustering import KMeans, KMeansModel\n",
    "from pyspark.mllib.clustering import GaussianMixture\n",
    "from numpy import array\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from time import time\n",
    "\n",
    "\n",
    "############## Mover a svm_utils\n",
    "def build_X1(x):\n",
    "    NI = len(x.features)\n",
    "    k = np.vstack((np.array(1).reshape((1, 1)), x.features.reshape((NI, 1))))\n",
    "    return LabeledPoint(x.label, k.T)\n",
    "\n",
    "\n",
    "def load_data(kdataset, kfold):\n",
    "    if kdataset == 1:\n",
    "        mat = scipy.io.loadmat('./data/ripley_5fold.mat')\n",
    "        name_dataset = 'Ripley'\n",
    "\n",
    "    if kdataset == 2:\n",
    "        mat = scipy.io.loadmat('./data/kwok_5fold.mat')\n",
    "        name_dataset = 'Kwok'\n",
    "\n",
    "    if kdataset == 3:\n",
    "        mat = scipy.io.loadmat('./data/twonorm_5fold.mat')\n",
    "        name_dataset = 'Twonorm'\n",
    "\n",
    "    if kdataset == 4:\n",
    "        mat = scipy.io.loadmat('./data/waveform_5fold.mat')\n",
    "        name_dataset = 'Waveform'\n",
    "\n",
    "    index_tr = mat['index_tr']\n",
    "    index_val = mat['index_val']\n",
    "    x_tr = mat['x_tr']\n",
    "    x_tst = mat['x_tst']\n",
    "    y_tr = mat['y_tr']\n",
    "    y_tst = mat['y_tst']\n",
    "\n",
    "    #import code\n",
    "    #code.interact(local=locals())\n",
    "    ind_tr = np.where(index_tr[:, kfold - 1] == 1)\n",
    "    ind_val = np.where(index_val[:, kfold - 1] == 1)\n",
    "\n",
    "    x_tr_ = x_tr[ind_tr]\n",
    "    y_tr_ = y_tr[ind_tr]\n",
    "\n",
    "    x_val_ = x_tr[ind_val]\n",
    "    y_val_ = y_tr[ind_val]\n",
    "\n",
    "    x_tst_ = x_tst\n",
    "    y_tst_ = y_tst\n",
    "\n",
    "    return x_tr_, y_tr_, x_val_, y_val_, x_tst_, y_tst_, name_dataset\n",
    "\n",
    "\n",
    "def get_inc_w(x, w, landa):\n",
    "    k = x.features\n",
    "    NI = len(k)\n",
    "    k = k.reshape(NI, 1)\n",
    "    ytr = x.label\n",
    "    yKw = ytr * np.dot(k.T, w)\n",
    "    if yKw < 1:\n",
    "        incw = -landa * w + ytr * k\n",
    "    else:\n",
    "        incw = -landa * w\n",
    "    return incw\n",
    "\n",
    "\n",
    "def train_linearSVM(Xtr1RDD, NI, C, eta, landa, Niter, Samplefraction):\n",
    "    w = np.zeros(NI + 1).reshape((NI + 1, 1))\n",
    "    N_added = 0\n",
    "    for k in range(0, Niter):\n",
    "        print k,\n",
    "        Xtr1RDDsampled = Xtr1RDD.sample(withReplacement=True, fraction=Samplefraction)\n",
    "        incwRDD = Xtr1RDDsampled.map(lambda x: get_inc_w(x, w, landa))\n",
    "        Nsample = incwRDD.count()\n",
    "        N_added += Nsample\n",
    "        eta = C / N_added\n",
    "        w += eta * incwRDD.reduce(lambda x, y: x + y)\n",
    "    return w\n",
    "\n",
    "\n",
    "def in_margin(x, w):\n",
    "    k = x.features\n",
    "    ytr = x.label\n",
    "    yKw = ytr * np.dot(k, w)\n",
    "    return yKw < 1\n",
    "\n",
    "\n",
    "def plot_linear_SVM(xtr, ytr, w, c, name_dataset):\n",
    "    \n",
    "    index1labels = np.where(ytr > 0)\n",
    "    index0labels = np.where(ytr <= 0)\n",
    "\n",
    "    plt.plot(xtr[index1labels, 0], xtr[index1labels, 1], 'b.')\n",
    "    plt.plot(xtr[index0labels, 0], xtr[index0labels, 1], 'r.')\n",
    "    NP = 100.0\n",
    "    SUP = np.zeros((NP, NP))\n",
    "    ejex = np.arange(NP).astype(float) / NP * 4.0 - 2.0\n",
    "    X_mesh = np.array([0, 0, 0]).reshape((1,3))\n",
    "    for m in range(0, int(NP)):\n",
    "        for n in range(0, int(NP)):\n",
    "            aux = np.array([1.0, ejex[m], ejex[n]]).reshape((1,3))\n",
    "            X_mesh = np.vstack((X_mesh, aux))\n",
    "\n",
    "    y_pred = np.dot(X_mesh, w)\n",
    "    y_pred = y_pred[1:]\n",
    "    Z = y_pred.reshape((NP,NP))\n",
    "    levels = np.arange(-1.0, 2.0 , 1.0)\n",
    "\n",
    "    CS = plt.contour(ejex, ejex, Z.T, levels, colors = 'k')\n",
    "    plt.clabel(CS, fontsize=9, inline=1)\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    plt.title(name_dataset)\n",
    "    plt.grid(True)\n",
    "    #plt.savefig(\"test.png\")\n",
    "    plt.plot(c[:, 0], c[:, 1], 'ro')\n",
    "    plt.show()\n",
    "\n",
    "def plot_hybrid_SVM(xtr, ytr, w, c, name_dataset):\n",
    "    index1labels = np.where(ytr > 0)\n",
    "    index0labels = np.where(ytr <= 0)\n",
    "    plt.plot(xtr[index1labels,0], xtr[index1labels,1],'b.')\n",
    "    plt.plot(xtr[index0labels,0], xtr[index0labels,1],'r.')\n",
    "    NI_a = xtr.shape[1]\n",
    "    NI_b = c.shape[0]\n",
    "    NI = NI_a + NI_b + 1\n",
    "    NP = 100.0\n",
    "    SUP = np.zeros((NP,NP))\n",
    "    ejex = np.arange(NP).astype(float) / NP * 4.0 - 2.0\n",
    "    X_mesh = np.zeros(NI).reshape((1,NI))\n",
    "    \n",
    "    NC = c.shape[0]\n",
    "    for m in range(0, int(NP)):\n",
    "        for n in range(0, int(NP)):\n",
    "            x1 = np.array([1.0, ejex[m], ejex[n]]).reshape((1,3))\n",
    "            X = np.kron(np.ones(NC).reshape((NC,1)),[ejex[m], ejex[n]])\n",
    "            e = X-c\n",
    "            e = e**2\n",
    "            e = e.sum(axis=1)\n",
    "            k = np.exp(-0.5 * e /sigma/sigma)\n",
    "            k = k.reshape((1, NC))\n",
    "            kx1 = np.hstack((x1,k))\n",
    "            X_mesh = np.vstack((X_mesh, kx1))\n",
    "\n",
    "    y_pred = np.dot(X_mesh, w)\n",
    "    y_pred = y_pred[1:]\n",
    "    Z = y_pred.reshape((NP,NP))\n",
    "    levels = np.arange(-1.0, 2.0 , 1.0)\n",
    "    CS = plt.contour(ejex, ejex, Z.T, levels, colors = 'k')\n",
    "    plt.clabel(CS, fontsize=9, inline=1)\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    plt.title(name_dataset)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def kernelG(x,c,sigma):\n",
    "    NC = c.shape[0]\n",
    "    X = np.kron(np.ones(NC).reshape((NC,1)),x.features)\n",
    "    e = X-c\n",
    "    e = e**2\n",
    "    e = e.sum(axis=1)\n",
    "    k = np.exp(-0.5 * e /sigma/sigma)\n",
    "    k = k.reshape((NC, 1))\n",
    "    return k\n",
    "\n",
    "def build_k(x, c, sigma):\n",
    "    NI = len(x.features)\n",
    "    k = np.vstack((np.array(1).reshape((1,1)),x.features.reshape((NI, 1))))\n",
    "    k = np.vstack((k,kernelG(x,c,sigma)))\n",
    "    x = LabeledPoint(x.label, k.T)\n",
    "    return x\n",
    "\n",
    "def build_kc(x, c, sigma):\n",
    "    #NI = len(x.features)\n",
    "    #k = np.vstack((np.array(1).reshape((1,1)),x.features.reshape((NI, 1))))\n",
    "    #import code\n",
    "    #code.interact(local=locals())\n",
    "\n",
    "    k = np.vstack((np.array(1).reshape((1,1)),kernelG(x,c,sigma)))\n",
    "    x = LabeledPoint(x.label, k.T)\n",
    "    return x\n",
    "\n",
    "def train_nonlinearSVM(KtrRDD, C, landa, Niter, Samplefraction):\n",
    "\n",
    "    x = KtrRDD.take(1)[0]\n",
    "    NI = len(x.features)\n",
    "    w = np.zeros(NI).reshape((NI,1))\n",
    "    N_added = 0\n",
    "    #KtrRDDsampled = KtrRDD.sample(withReplacement=True, fraction=Samplefraction)\n",
    "\n",
    "    for k in range(0,Niter):\n",
    "        print k, \n",
    "        KtrRDDsampled = KtrRDD.sample(withReplacement=True, fraction=Samplefraction)\n",
    "        incwRDD = KtrRDDsampled.map(lambda x: get_inc_w(x, w, landa))\n",
    "        Nsample = incwRDD.count()\n",
    "        N_added += Nsample \n",
    "        eta = C/N_added\n",
    "        w += eta * incwRDD.reduce(lambda x, y: x + y)\n",
    "    print \"Fin!\"\n",
    "    return w\n",
    "\n",
    "\n",
    "def predict(x, w):\n",
    "    k = x.features.reshape((1,len(x.features)))\n",
    "    y_pred = np.dot(k, w)\n",
    "    return y_pred\n",
    "\n",
    "def plot_ROC(Ytr, Ytst):\n",
    "    fpr_tr, tpr_tr, th_tr = roc_curve(np.array(Ytr)[:,0], np.array(Ytr)[:,1])\n",
    "    auc_tr = auc(fpr_tr, tpr_tr)\n",
    "    #plt.plot(fpr_tr, tpr_tr,'r')\n",
    "\n",
    "    fpr_tst, tpr_tst, th_tst = roc_curve(np.array(Ytst)[:,0], np.array(Ytst)[:,1])\n",
    "    auc_tst = auc(fpr_tst, tpr_tst)\n",
    "    #plt.plot(fpr_tst, tpr_tst,'g')\n",
    "\n",
    "    '''\n",
    "    plt.xlabel('fpr')\n",
    "    plt.ylabel('tpr')\n",
    "    plt.title(name_dataset)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    '''\n",
    "    return auc_tst\n",
    "\n",
    "                  \n",
    "def train_kernelgrad(XtrRDD, XvalRDD, XtstRDD, sigma, C, NC, name_dataset, Niter, Samplefraction):\n",
    "    \n",
    "    time_ini = time()\n",
    "    eta = C\n",
    "    landa = 1.0 / C\n",
    "    NPtr = XtrRDD.count()\n",
    "    #NPval = XvalRDD.count()\n",
    "    #NPtst = XtstRDD.count()\n",
    "    NI = len(XtrRDD.take(1)[0].features)\n",
    "    XtrRDD.cache()\n",
    "    XtstRDD.cache()\n",
    "    T = NPtr\n",
    "    \n",
    "    #print NPtr, NPtst, NI\n",
    "\n",
    "    #print \"Training the linear SVM model during %d iterations\" % Niter\n",
    "\n",
    "    Xtr1RDD = XtrRDD.map(lambda x: build_X1(x)).cache()\n",
    "    #Xtst1RDD = XtstRDD.map(lambda x: build_X1(x)).cache()\n",
    "    #w = train_linearSVM(Xtr1RDD, NI, C, eta, landa, Niter, Samplefraction)\n",
    "    #print \"Done!\"\n",
    "\n",
    "    #xtr = np.array(XtrRDD.map(lambda x: x.features).collect())\n",
    "    #ytr = np.array(XtrRDD.map(lambda x: x.label).collect())\n",
    "\n",
    "    print \"Clustering data...\"\n",
    "    #SV_RDD = Xtr1RDD.filter(lambda x: in_margin(x, w))\n",
    "    clusters = KMeans.train(Xtr1RDD.map(lambda x: x.features[1:len(x.features)]), NC, maxIterations=20, runs=20, initializationMode=\"random\")\n",
    "    c = np.array(clusters.centers)\n",
    "\n",
    "    '''\n",
    "    if kdataset == 1 or kdataset == 2:   # el resto no se pueden pintar\n",
    "        #SVM.plot_linear_SVM(xtr, ytr, w, c)\n",
    "        plot_linear_SVM(xtr, ytr, w, c, name_dataset)\n",
    "    '''\n",
    "    \n",
    "    print \"Building the kernel expansion...\"    \n",
    "    KtrRDD = XtrRDD.map(lambda x: build_kc(x, c, sigma)).cache()\n",
    "    KvalRDD = XvalRDD.map(lambda x: build_kc(x, c, sigma)).cache()\n",
    "    KtstRDD = XtstRDD.map(lambda x: build_kc(x, c, sigma)).cache()\n",
    "\n",
    "    print \"Training the hybrid SVM model during %d iterations\" % Niter\n",
    "\n",
    "    w = train_nonlinearSVM(KtrRDD, C, landa, Niter, Samplefraction)\n",
    "\n",
    "    '''\n",
    "    xtr = np.array(XtrRDD.map(lambda x: x.features).collect())\n",
    "    ytr = np.array(XtrRDD.map(lambda x: x.label).collect())\n",
    "    if kdataset == 1 or kdataset == 2:   # el resto no se pueden pintar \n",
    "        plot_hybrid_SVM(xtr, ytr, w, c, name_dataset)\n",
    "    '''\n",
    "    print \"Predicting and evaluating...\"\n",
    "\n",
    "    #y_pred_trRDD = KtrRDD.map(lambda x: (x.label, predict(x, w)[0][0]))\n",
    "    y_pred_valRDD = KvalRDD.map(lambda x: (x.label, predict(x, w)[0][0]))\n",
    "    y_pred_tstRDD = KtstRDD.map(lambda x: (x.label, predict(x, w)[0][0]))\n",
    "\n",
    "    #Ytr = y_pred_trRDD.collect()\n",
    "    Yval = y_pred_valRDD.collect()\n",
    "    Ytst = y_pred_tstRDD.collect()\n",
    "\n",
    "    #auc_tst = plot_ROC(Ytr, Ytst)\n",
    "    elapsed_time = time() - time_ini\n",
    "\n",
    "    fpr_val, tpr_val, th_val = roc_curve(np.array(Yval)[:,0], np.array(Yval)[:,1])\n",
    "    auc_val = auc(fpr_val, tpr_val)\n",
    "\n",
    "    fpr_tst, tpr_tst, th_tst = roc_curve(np.array(Ytst)[:,0], np.array(Ytst)[:,1])\n",
    "    auc_tst = auc(fpr_tst, tpr_tst)\n",
    "\n",
    "    print \"AUCval = %f, AUCtst = %f\" % (auc_val, auc_tst)\n",
    "    print \"Elapsed_time = %f\" % elapsed_time\n",
    "    return auc_val, auc_tst, elapsed_time\n",
    "\n",
    "\n",
    "def train_hybridSVM(XtrRDD, XvalRDD, XtstRDD, sigma, C, NC, name_dataset, Niter, Samplefraction):\n",
    "    \n",
    "    time_ini = time()\n",
    "    eta = C\n",
    "    landa = 1.0 / C\n",
    "    NPtr = XtrRDD.count()\n",
    "    #NPval = XvalRDD.count()\n",
    "    #NPtst = XtstRDD.count()\n",
    "    NI = len(XtrRDD.take(1)[0].features)\n",
    "    XtrRDD.cache()\n",
    "    XtstRDD.cache()\n",
    "    T = NPtr\n",
    "    \n",
    "    #print NPtr, NPtst, NI\n",
    "\n",
    "    print \"Training the linear SVM model during %d iterations\" % Niter\n",
    "\n",
    "    Xtr1RDD = XtrRDD.map(lambda x: build_X1(x)).cache()\n",
    "    #Xtst1RDD = XtstRDD.map(lambda x: build_X1(x)).cache()\n",
    "    w = train_linearSVM(Xtr1RDD, NI, C, eta, landa, Niter, Samplefraction)\n",
    "    print \"Done!\"\n",
    "\n",
    "    xtr = np.array(XtrRDD.map(lambda x: x.features).collect())\n",
    "    ytr = np.array(XtrRDD.map(lambda x: x.label).collect())\n",
    "\n",
    "    print \"Clustering SVs...\"\n",
    "    SV_RDD = Xtr1RDD.filter(lambda x: in_margin(x, w))\n",
    "    clusters = KMeans.train(SV_RDD.map(lambda x: x.features[1:len(x.features)]), NC, maxIterations=20, runs=20, initializationMode=\"random\")\n",
    "    c = np.array(clusters.centers)\n",
    "\n",
    "    '''\n",
    "    if kdataset == 1 or kdataset == 2:   # el resto no se pueden pintar\n",
    "        #SVM.plot_linear_SVM(xtr, ytr, w, c)\n",
    "        plot_linear_SVM(xtr, ytr, w, c, name_dataset)\n",
    "    '''\n",
    "    \n",
    "    print \"Building the kernel expansion...\"    \n",
    "    KtrRDD = XtrRDD.map(lambda x: build_k(x, c, sigma)).cache()\n",
    "    KvalRDD = XvalRDD.map(lambda x: build_k(x, c, sigma)).cache()\n",
    "    KtstRDD = XtstRDD.map(lambda x: build_k(x, c, sigma)).cache()\n",
    "\n",
    "    print \"Training the hybrid SVM model during %d iterations\" % Niter\n",
    "\n",
    "    w = train_nonlinearSVM(KtrRDD, C, landa, Niter, Samplefraction)\n",
    "\n",
    "    '''\n",
    "    xtr = np.array(XtrRDD.map(lambda x: x.features).collect())\n",
    "    ytr = np.array(XtrRDD.map(lambda x: x.label).collect())\n",
    "    if kdataset == 1 or kdataset == 2:   # el resto no se pueden pintar \n",
    "        plot_hybrid_SVM(xtr, ytr, w, c, name_dataset)\n",
    "    '''\n",
    "    print \"Predicting and evaluating...\"\n",
    "\n",
    "    #y_pred_trRDD = KtrRDD.map(lambda x: (x.label, predict(x, w)[0][0]))\n",
    "    y_pred_valRDD = KvalRDD.map(lambda x: (x.label, predict(x, w)[0][0]))\n",
    "    y_pred_tstRDD = KtstRDD.map(lambda x: (x.label, predict(x, w)[0][0]))\n",
    "\n",
    "    #Ytr = y_pred_trRDD.collect()\n",
    "    Yval = y_pred_valRDD.collect()\n",
    "    Ytst = y_pred_tstRDD.collect()\n",
    "\n",
    "    #auc_tst = plot_ROC(Ytr, Ytst)\n",
    "    elapsed_time = time() - time_ini\n",
    "\n",
    "    fpr_val, tpr_val, th_val = roc_curve(np.array(Yval)[:,0], np.array(Yval)[:,1])\n",
    "    auc_val = auc(fpr_val, tpr_val)\n",
    "\n",
    "    fpr_tst, tpr_tst, th_tst = roc_curve(np.array(Ytst)[:,0], np.array(Ytst)[:,1])\n",
    "    auc_tst = auc(fpr_tst, tpr_tst)\n",
    "\n",
    "    print \"AUCval = %f, AUCtst = %f\" % (auc_val, auc_tst)\n",
    "    print \"Elapsed_time = %f\" % elapsed_time\n",
    "    return auc_val, auc_tst, elapsed_time\n",
    "\n",
    "\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "# definir variable de usuario y ejecutar condicionalmente cualquier código que dependa del contexto de ejecución\n",
    "\n",
    "user = 'navia'\n",
    "#user = 'roberto'\n",
    "\n",
    "#modelo = 'hybrid' \n",
    "#modelo = 'kernelgrad' \n",
    "\n",
    "if user == 'roberto':\n",
    "    # definir sc\n",
    "    import findspark\n",
    "    findspark.init()\n",
    "    from pyspark import SparkConf, SparkContext\n",
    "    conf = (SparkConf().setMaster(\"local[4]\").setAppName(\"My app\").set(\"spark.executor.memory\", \"2g\"))\n",
    "    sc = SparkContext(conf = conf)\n",
    "\n",
    "if user == 'navia':\n",
    "    #sc.addPyFile(\"/export/usuarios01/navia/spark/SVM_spark/common/lib/svm_utils.py\")\n",
    "    #sc.addPyFile(\"/export/usuarios01/navia/spark/SVM_spark/common/lib/quadtree_utils.py\")   \n",
    "    #import svm_utils as SVM_UTILS\n",
    "    #import quadtree_utils as QUADTREE\n",
    "    import numpy as np\n",
    "    from pyspark.mllib.regression import LabeledPoint\n",
    "    import pickle\n",
    "    %matplotlib inline\n",
    "\n",
    "overwrite_results = False # overwrite results\n",
    "\n",
    "kdatasets = [1, 2, 3, 4]\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "\n",
    "#Niter = 2\n",
    "Nnodes = 32\n",
    "Samplefraction = 0.05\n",
    "\n",
    "Niter = 150\n",
    "NCs = [5, 10, 25, 50, 100, 200]\n",
    "\n",
    "#Niter = 300\n",
    "#NCs = [50, 100, 200]\n",
    "\n",
    "\n",
    "kdatasets = [1]\n",
    "folds = [1, 2]\n",
    "Niters = [50, 100]\n",
    "NCs = [5, 10]\n",
    "modelos = ['hybrid', 'kernelgrad']\n",
    "modelos = ['kernelgrad']\n",
    "\n",
    "for modelo in modelos:\n",
    "    for kdataset in kdatasets:\n",
    "        for kfold in folds:\n",
    "            for Niter in Niters:\n",
    "                x_tr, y_tr, x_val, y_val, x_tst, y_tst, name_dataset = load_data(kdataset, kfold)\n",
    "                NI = x_tr.shape[1]\n",
    "                sigma = sqrt(NI)\n",
    "                C = 10.0\n",
    "                XtrRDD = sc.parallelize(np.hstack((y_tr, x_tr)), Nnodes).map(lambda x: LabeledPoint(x[0], x[1:len(x)]))\n",
    "                XvalRDD = sc.parallelize(np.hstack((y_val, x_val)), Nnodes).map(lambda x: LabeledPoint(x[0], x[1:len(x)]))\n",
    "                XtstRDD = sc.parallelize(np.hstack((y_tst, x_tst)), Nnodes).map(lambda x: LabeledPoint(x[0], x[1:len(x)]))\n",
    "                for NC in NCs:\n",
    "                    print \"Dataset = %s, modelo = %s, kfold = %d, Niter = %d, NC = %d\" % (name_dataset, modelo, kfold, Niter, NC)\n",
    "                    filename = './results/dataset_' + str(kdataset) + '_modelo_' + modelo + '_NC_' + str(NC) + '_Niter_' + str(Niter) + '_kfold_' + str(kfold) + '.pkl'\n",
    "                    try:\n",
    "                        f = open(filename,'r')\n",
    "                        f.close()\n",
    "                        file_exists = True\n",
    "                    except:\n",
    "                        file_exists = False\n",
    "                        pass\n",
    "                    execute = False\n",
    "                    if file_exists:\n",
    "                        if overwrite_results:\n",
    "                            execute = True\n",
    "                    else:\n",
    "                        execute = True                                  \n",
    "                    if execute:\n",
    "                        if modelo == 'hybrid':\n",
    "                            auc_val, auc_tst, exe_time = train_hybridSVM(XtrRDD, XvalRDD, XtstRDD, sigma, C, NC, name_dataset, Niter, Samplefraction)\n",
    "                        if modelo == 'kernelgrad':\n",
    "                            auc_val, auc_tst, exe_time = train_kernelgrad(XtrRDD, XvalRDD, XtstRDD, sigma, C, NC, name_dataset, Niter, Samplefraction)\n",
    "                        with open(filename, 'w') as f:\n",
    "                            pickle.dump([auc_val, auc_tst, time], f)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
